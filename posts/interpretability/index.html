<!DOCTYPE html>
<html lang="en-uk">
    
    


    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.74.3" />

    
    
    

<title>A banal machine learning system where interpretability and explainability matter • Machine learning in real life</title>
<meta name="google-site-verification" content="TCP3Xybh5xzOfqotpAWEcZvWXDkTewIEh8oUbcnpT3U" />
<meta name="description" content="" />
<meta itemprop="description" content="As algorithmic systems become more prevalent, the need to understand them grows (Interpretability report from Cloudera)." />
<meta property="og:description" content="As algorithmic systems become more prevalent, the need to understand them grows (Interpretability report from Cloudera)." />
<meta name="twitter:description" content="As algorithmic systems become more prevalent, the need to understand them grows (Interpretability report from Cloudera)." />
<meta name="keywords" content="nastasia saby, nastasia, saby, engineer, data, deep learning, shallow learning, learning, machine, tests, unit, people, analytics, book, career, concepts, data science, machine learning, pomodoro, issue, failure, data drift, model drift, drift, mlops, dataops, devops, sexism, unit tests, improve, mistakes">
<meta name="application-name" content="A banal machine learning system where interpretability and explainability matter | Machine learning in real life" />
<meta property="og:site_name" content="" />
<meta itemprop="name" content="A banal machine learning system where interpretability and explainability matter | Machine learning in real life" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://mlinreallife.github.io/Logo3.png"/>

<meta name="twitter:title" content="A banal machine learning system where interpretability and explainability matter"/>
<meta name="twitter:description" content="As algorithmic systems become more prevalent, the need to understand them grows (Interpretability report from Cloudera)."/>
<meta name="twitter:site" content="@saby_nastasia"/>

<meta property="og:title" content="A banal machine learning system where interpretability and explainability matter" />
<meta property="og:description" content="As algorithmic systems become more prevalent, the need to understand them grows (Interpretability report from Cloudera)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mlinreallife.github.io/posts/interpretability/" />
<meta property="og:image" content="https://mlinreallife.github.io/Logo3.png"/>
<meta property="article:published_time" content="2021-01-06T06:11:10+02:00" />
<meta property="article:modified_time" content="2021-01-06T07:11:46+01:00" />

<base href="https://mlinreallife.github.io/posts/interpretability/">
<link rel="canonical" href="https://mlinreallife.github.io/posts/interpretability/" itemprop="url" />
<meta name="url" content="https://mlinreallife.github.io/posts/interpretability/" />
<meta name="twitter:url" content="https://mlinreallife.github.io/posts/interpretability/" />
<meta property="og:url" content="https://mlinreallife.github.io/posts/interpretability/" />
<meta property="og:locale" content="en">
<meta name="language" content="English">


<meta itemprop="image" content="https://mlinreallife.github.io" />
<meta property="og:image" content="https://mlinreallife.github.io" />

<meta property="og:updated_time" content=2021-01-06T07:11:46&#43;0100 />
Sitemap & RSS Feed Tags
<link rel="sitemap" type="application/xml" title="Sitemap" href="https://mlinreallife.github.iositemap.xml" />



    






<link rel="stylesheet" href="https://mlinreallife.github.io/scss/hyde-hyde.3081c4981fb69a2783dd36ecfdd0e6ba7a158d4cbfdd290ebce8f78ba0469fc6.css" integrity="sha256-MIHEmB&#43;2mieD3Tbs/dDmunoVjUy/3SkOvOj3i6BGn8Y=">


<link rel="stylesheet" href="https://mlinreallife.github.io/scss/print.2744dcbf8a0b2e74f8a50e4b34e5f441be7cf93cc7de27029121c6a09f9e77bc.css" integrity="sha256-J0Tcv4oLLnT4pQ5LNOX0Qb58&#43;TzH3icCkSHGoJ&#43;ed7w=" media="print">



    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" type="image/png" sizes="144x144" href="https://mlinreallife.github.io/favicon.ico">
    <link rel="shortcut icon" type="image/png" href="https://mlinreallife.github.io/favicon.ico">
    
    

</head>


    <body class=" ">
    
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
      <h1 class="site__title">
        <a href="https://mlinreallife.github.io">Machine learning in real life</a>
      </h1>
      
      
        <div class="author-image">
          <img src="https://www.gravatar.com/avatar/f1e09bf0b41e5559ff4623401378a1f8?s=240&d=mp" class="img--circle img--headshot element--center" alt="gravatar">
        </div>
      
      <h3 class="site__description">
         Nastasia Saby 
      </h3>
    </div>
    <div class="collapsible-menu">
      <input type="checkbox" id="menuToggle">
      <label for="menuToggle">Machine learning in real life</label>
      <div class="menu-content">
        <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="https://mlinreallife.github.io/posts/">
						<span>Posts</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="https://mlinreallife.github.io/newsletter/">
						<span>Newsletter</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="https://mlinreallife.github.io/nastasia_saby/">
						<span>About Me Nastasia Saby</span>
					</a>
				</li>
			 
		
	</ul>
</div>

        <section class="social">
	
	<a href="https://twitter.com/@saby_nastasia" rel="me"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
</section>

      </div>
    </div>
    


  </div>
</div>

        <div class="content container">
            
    
<article>
  <header>
    <h1>A banal machine learning system where interpretability and explainability matter</h1>
    
    
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Jan 06, 2021
    
    
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 3 min read
</div>


  </header>
  
  
  <div class="post">
    <blockquote>
<p>As algorithmic systems become more prevalent, the need to understand them grows (Interpretability report from Cloudera).</p>
</blockquote>
<p>Interpretability and explainability are used for ethics purposes.</p>
<p>It can serve other interests: medical diagnosis, safety decisions, etc.
It can also be used for any kind of ordinary applications.</p>
<p>I would like to tell you a story. Once upon a time, there was a banal machine learning system. For this one, interpretability and explainability mattered.</p>
<h2 id="a-story-about-predicting-breakdowns">A story about predicting breakdowns</h2>
<p>Suppose you are working with a system that predicts breakdowns for lifts.</p>
<p>The system is not a complete black box such as a neural network. However, it is not a complete white box such as a linear regression.</p>
<p>You are dealing with a random forest algorithm.</p>
<p>You have different events:</p>
<ul>
<li>The time between two floors</li>
<li>The time between the moment a door opens and the moment it closes</li>
</ul>
<p>All these data are inputs of the algorithm. When the system predicts a breakdown, technicians must trust it. It is easier to intervene when you have the breakdown than when you suppose you will have one.</p>
<p>Imagine you trying to solve a bug that you think you will have but you don’t have yet. For sure, it is challenging.</p>
<h2 id="use-interpretability-to-enhance-your-system">Use interpretability to enhance your system</h2>
<p>Interpretability helps to gain the technician’s trust.</p>
<p>Interpretability can be global and local.</p>
<p>You can give local interpretability to any machine learning system. There are several methods and tools to do that.</p>
<p>You can detect correlations. For instance, when the time between two floors exceeds two minutes, you might get a breakdown soon.</p>
<p>In this case, interpretability gives some explanations. However, it is not enough.</p>
<h2 id="interpretability-has-limits">Interpretability has limits</h2>
<p>Indeed, you know why the system has predicted a breakdown. The answer is: the time between two floors exceeds two minutes.</p>
<p>That’s not so bad.</p>
<p>But, the breakdown still doesn’t exist. You have a hint about your bug. But it still doesn’t exist. You have no way to find the deep root cause of it. You have no idea how to solve it and where to start.</p>
<p>Your hint— the time between two floors exceeds two minutes — does not help.
Interpretability could be great. But if your inputs are not easy to interpret anyway, that is not enough.</p>
<p>Moreover, most of the time, techniques and tools for interpretability give correlations, no causalities.</p>
<h2 id="explainability-a-way-to-go-beyond-these-limits">Explainability: a way to go beyond these limits</h2>
<p>We need interpretability and confidence as a global issue. We need human explainability.</p>
<blockquote>
<p>Interpretability is about being able to discern the mechanics without necessarily knowing why. Explainability is being able to quite literally explain what is happening (Machine Learning Explainability vs Interpretability: Two concepts that could help restore trust in AI).</p>
</blockquote>
<p>The idea is to build a reliable and interpretable system.</p>
<p>In our story, you can imagine a way to predict the root cause of a future breakdown. You could have different probabilities about the potential reasons for the breakdown.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Interpretability and explainability are not only for Google, medical analysis, or military purposes.</p>
<p>In our case, explaining a prediction helps to believe it.</p>
<p>There are other advantages to interpretability and explainability.</p>
<blockquote>
<p>The more you understand the algorithm, the more you can improve it (Cloudera report).</p>
</blockquote>
<p>Thank you for reading. Feel free to contact me on <a href="https://twitter.com/saby_nastasia">Twitter</a> if you want to discuss that.</p>

  </div>
  

<div class="navigation navigation-single">
    
    <a href="https://mlinreallife.github.io/posts/press_review_4/" class="navigation-prev">
      <i aria-hidden="true" class="fa fa-chevron-left"></i>
      <span class="navigation-tittle">Issue 4: Resources to get an overview of a machine learning project</span>
    </a>
    
    
    <a href="https://mlinreallife.github.io/posts/press_review_5/" class="navigation-next">
      <span class="navigation-tittle">Issue 5: Resources to get started with Kubernetes</span>
      <i aria-hidden="true" class="fa fa-chevron-right"></i>
    </a>
    
</div>


  

  
    


</article>


        </div>
        
    

<script defer src="https://use.fontawesome.com/releases/v5.11.2/js/all.js" integrity="sha384-b3ua1l97aVGAPEIe48b4TC60WUQbQaGi2jqAWM90y0OZXZeyaTCWtBTKtjW2GXG1" crossorigin="anonymous"></script>




    



    </body>
</html>
