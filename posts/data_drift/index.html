<!DOCTYPE html>
<html lang="en-uk">
    
    


    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.74.3" />

    
    
    

<title>Data drift monitoring: hypothesis tests or statistical distances? • Machine learning in real life</title>
<meta name="description" content="" />
<meta itemprop="description" content="" />
<meta property="og:description" content="" />
<meta name="twitter:description" content="" />

<meta name="application-name" content="Data drift monitoring: hypothesis tests or statistical distances? | Machine learning in real life" />
<meta property="og:site_name" content="" />
<meta itemprop="name" content="Data drift monitoring: hypothesis tests or statistical distances? | Machine learning in real life" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://mlinreallife.github.io/data_versioning.png"/>

<meta name="twitter:title" content="Data drift monitoring: hypothesis tests or statistical distances?"/>
<meta name="twitter:description" content="Today, I would like to talk about a tough and important subject in my opinion: data drift monitoring.
Data drift monitoring is critical. Data drift leads to model performance decrease. At the same time, IMHO, it&rsquo;s hard to get a satisfactory solution for at least two reasons:
 It&rsquo;s challenging to develop a custom solution. It&rsquo;s laborious to know if it is preferable to compute statistical distances or try to reject a hypothesis test with a p-value?"/>
<meta name="twitter:site" content="@saby_nastasia"/>

<meta property="og:title" content="Data drift monitoring: hypothesis tests or statistical distances?" />
<meta property="og:description" content="Today, I would like to talk about a tough and important subject in my opinion: data drift monitoring.
Data drift monitoring is critical. Data drift leads to model performance decrease. At the same time, IMHO, it&rsquo;s hard to get a satisfactory solution for at least two reasons:
 It&rsquo;s challenging to develop a custom solution. It&rsquo;s laborious to know if it is preferable to compute statistical distances or try to reject a hypothesis test with a p-value?" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mlinreallife.github.io/posts/data_drift/" />
<meta property="og:image" content="https://mlinreallife.github.io/data_versioning.png"/>
<meta property="article:published_time" content="2020-09-30T13:01:10+02:00" />
<meta property="article:modified_time" content="2020-10-19T10:01:28+02:00" />

<base href="https://mlinreallife.github.io/posts/data_drift/">
<link rel="canonical" href="https://mlinreallife.github.io/posts/data_drift/" itemprop="url" />
<meta name="url" content="https://mlinreallife.github.io/posts/data_drift/" />
<meta name="twitter:url" content="https://mlinreallife.github.io/posts/data_drift/" />
<meta property="og:url" content="https://mlinreallife.github.io/posts/data_drift/" />
<meta property="og:locale" content="en">
<meta name="language" content="English">


<meta itemprop="image" content="https://mlinreallife.github.io" />
<meta property="og:image" content="https://mlinreallife.github.io" />

<meta property="og:updated_time" content=2020-10-19T10:01:28&#43;0200 />
Sitemap & RSS Feed Tags
<link rel="sitemap" type="application/xml" title="Sitemap" href="https://mlinreallife.github.iositemap.xml" />



    






<link rel="stylesheet" href="https://mlinreallife.github.io/scss/hyde-hyde.3081c4981fb69a2783dd36ecfdd0e6ba7a158d4cbfdd290ebce8f78ba0469fc6.css" integrity="sha256-MIHEmB&#43;2mieD3Tbs/dDmunoVjUy/3SkOvOj3i6BGn8Y=">


<link rel="stylesheet" href="https://mlinreallife.github.io/scss/print.2744dcbf8a0b2e74f8a50e4b34e5f441be7cf93cc7de27029121c6a09f9e77bc.css" integrity="sha256-J0Tcv4oLLnT4pQ5LNOX0Qb58&#43;TzH3icCkSHGoJ&#43;ed7w=" media="print">



    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://mlinreallife.github.io/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="https://mlinreallife.github.io/favicon.png">
    
    

</head>


    <body class=" ">
    
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="https://mlinreallife.github.io">Machine learning in real life</a>
      </span>
      
      
        <div class="author-image">
          <img src="https://www.gravatar.com/avatar/f1e09bf0b41e5559ff4623401378a1f8?s=240&d=mp" class="img--circle img--headshot element--center" alt="gravatar">
        </div>
      
      <p class="site__description">
         Nastasia Saby 
      </p>
    </div>
    <div class="collapsible-menu">
      <input type="checkbox" id="menuToggle">
      <label for="menuToggle">Machine learning in real life</label>
      <div class="menu-content">
        <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="https://mlinreallife.github.io/posts/">
						<span>Posts</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="https://mlinreallife.github.io/newsletter/">
						<span>Newsletter</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="https://mlinreallife.github.io/about/">
						<span>About</span>
					</a>
				</li>
			 
		
	</ul>
</div>

        <section class="social">
	
	<a href="https://twitter.com/@saby_nastasia" rel="me"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
</section>

      </div>
    </div>
    


  </div>
</div>

        <div class="content container">
            
    
<article>
  <header>
    <h1>Data drift monitoring: hypothesis tests or statistical distances?</h1>
    
    
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Sep 30, 2020
    
    
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 3 min read
</div>


  </header>
  
  
  <div class="post">
    <p>Today, I would like to talk about a tough and important subject in my opinion: data drift monitoring.</p>
<p>Data drift monitoring is critical. Data drift leads to model performance decrease.
At the same time, IMHO, it&rsquo;s hard to get a satisfactory solution for at least two reasons:</p>
<ul>
<li>It&rsquo;s challenging to develop a custom solution.</li>
<li>It&rsquo;s laborious to know if it is preferable to compute statistical distances or try to reject a hypothesis test with a p-value?</li>
</ul>
<h2 id="what-is-data-drift">What is data drift?</h2>
<p><em>Data drift</em> is when you get such a change in your coming data that it can impact the performance of the model.</p>
<p>What I name <em>data drift</em> has synonyms such as <em>data shift</em>.
The word gets also many subnames to describe the specificities of each kind of <em>data drift</em>. You can get <em>gradual drift</em>, <em>abrupt drift</em>, <em>extended drift</em>, etc.</p>
<p>I think it&rsquo;s important to understand that there are many kinds of drifts and that they don&rsquo;t mean the same thing.</p>
<ul>
<li>A short but abrupt drift can be due to a problem in your data.</li>
<li>An extended abrupt drift can be due to a recession.</li>
<li>A seasonal drift can be due to the seasons.</li>
</ul>
<p>You can see all these nuances in the paper <a href="https://www.researchgate.net/publication/283761478_Characterizing_Concept_Drift">Characterizing Concept Drift</a> by Geoffrey I Webb, Roy Hyde, Hong Cao, Hai-Long Nguyen and François Petitjean.</p>
<h2 id="how-to-monitor-data-drift">How to monitor data drift?</h2>
<p>There are two solutions that are presented in the literature.</p>
<h3 id="statistical-distances">Statistical distances</h3>
<p>I get the impression that the favourite one is computing a distance measure between your different distributions.
You can use <em>wasserstein distance</em>, <em>mahalanobis distance</em>, <em>euclidean distance</em> etc. Among all of them, you must choose one. <em>Hellinger distance</em> is the preferred one of the paper <a href="https://www.researchgate.net/publication/327539525_Survey_of_distance_measures_for_quantifying_concept_drift_and_shift_in_numeric_data">Survey of distance measures for quantifying concept drift and shift in numeric data</a> written by Igor Goldenberg and Geoffrey I Webb.</p>
<p>They built different tests and find <em>Hellinger distance</em> more suitable because this distance is <em>robust</em> and <em>provide an &ldquo;absolute&rdquo; value, bounded between 0 and 1</em>.</p>
<p>Martin Schmidtz, the author of the article <a href="https://rapidminer.com/blog/how-to-detect-drifting-models/">How to Detect Drifting Models</a> explains that he doesn&rsquo;t think hypothesis tests useful for monitoring data drift:</p>
<blockquote>
<p>A low p-value only means that we cannot confirm it. This does not mean that we can prove that these distributions are different! Not very useful…
<cite>Martin Schmidtz</cite></p>
</blockquote>
<blockquote>
<p>So I asked myself—isn’t there something else to use? And there is—distance measures for distributions!
<cite>Martin Schmidtz</cite></p>
</blockquote>
<p>The big winner seems to be: statistical distances.</p>
<h3 id="hypothesis-tests">Hypothesis tests</h3>
<p>A paper struck me recently: <a href="https://arxiv.org/pdf/2007.06299.pdf">Monitoring and explainability of models in production</a> written by Janis Klaise, Arnaud Van Looveren, Clive Cox, Giovanni Vacanti and Alexandru Coca.</p>
<p>The authors speak about hypothesis tests to monitor data drift.</p>
<p>I had a discussion with one of the authors and found his explanation quite clarifying.</p>
<p>The distance between two distributions doesn&rsquo;t tell you when you have to be concerned. You must set a threshold to send an alert. This is what a statistical test does. <em>p-value</em> is surely not the best metric. But at least, it&rsquo;s easier to understand a <em>p-value</em> than a <em>wasserstein distance</em>.</p>
<p>The paper talks about a library I definitely want to test: <a href="https://github.com/SeldonIO/alibi-detect">alibi-detect</a>. It was designed to detect data drift with hypothesis tests: <em>Kolmogorov-Smirnov</em> and <em>Maximum Mean Discrepancy</em>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>To answer the question previously asked <em>Data drift monitoring: hypothesis tests or statistical distances?</em>, I don&rsquo;t know. <em>Data Drift</em> is currently an open research area. I guess it&rsquo;s normal not to know. What I definitely believe is that it&rsquo;s a tough but important topic. Then I would say it&rsquo;s better to do something - hypothesis tests or statistical distances - than nothing.</p>
<p><a href="https://azure.microsoft.com/fr-fr/services/machine-learning/">Azure Machine learning</a> or <a href="https://www.monalabs.io/">Mona Labs</a> proposes off-the-shelf solutions.</p>
<p>Thank you for reading.</p>

  </div>
  

<div class="navigation navigation-single">
    
    <a href="https://mlinreallife.github.io/posts/streamlit/" class="navigation-prev">
      <i aria-hidden="true" class="fa fa-chevron-left"></i>
      <span class="navigation-tittle">Doing web without JavaScript, HTML nor CSS for data science</span>
    </a>
    
    
    <a href="https://mlinreallife.github.io/posts/pomodoro/" class="navigation-next">
      <span class="navigation-tittle">Stay focus with Pomodoro</span>
      <i aria-hidden="true" class="fa fa-chevron-right"></i>
    </a>
    
</div>


  

  
    


</article>


        </div>
        
    

<script defer src="https://use.fontawesome.com/releases/v5.11.2/js/all.js" integrity="sha384-b3ua1l97aVGAPEIe48b4TC60WUQbQaGi2jqAWM90y0OZXZeyaTCWtBTKtjW2GXG1" crossorigin="anonymous"></script>




    



    </body>
</html>
